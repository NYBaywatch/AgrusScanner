---
phase: 02-core-scanning-engine
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src-tauri/src/scanner/ping.rs
  - src-tauri/src/scanner/dns.rs
autonomous: true

must_haves:
  truths:
    - "Ping sweep discovers live hosts on a /24 subnet"
    - "Ping sweep runs concurrently with bounded semaphore (not sequential)"
    - "Live hosts have hostname resolved via async reverse DNS"
    - "Ping sweep respects cancellation token and stops gracefully"
  artifacts:
    - path: "src-tauri/src/scanner/ping.rs"
      provides: "Concurrent ICMP ping sweep engine"
      exports: ["ping_sweep"]
    - path: "src-tauri/src/scanner/dns.rs"
      provides: "Async reverse DNS resolution"
      exports: ["reverse_dns_lookup"]
  key_links:
    - from: "src-tauri/src/scanner/ping.rs"
      to: "surge-ping"
      via: "ICMP echo requests"
      pattern: "surge_ping"
    - from: "src-tauri/src/scanner/ping.rs"
      to: "tokio::sync::Semaphore"
      via: "bounded concurrency"
      pattern: "Semaphore::new"
    - from: "src-tauri/src/scanner/dns.rs"
      to: "hickory-resolver"
      via: "async DNS lookup"
      pattern: "hickory_resolver"
    - from: "src-tauri/src/scanner/ping.rs"
      to: "tokio_util::sync::CancellationToken"
      via: "cooperative cancellation"
      pattern: "CancellationToken"
---

<objective>
Implement the ICMP ping sweep engine with bounded concurrency, cancellation support, and async reverse DNS hostname resolution.

Purpose: Ping sweep is the first scan step -- discover which hosts are alive before port scanning them. This must be fast (concurrent), safe (bounded), and cancellable.
Output: `scanner/ping.rs` and `scanner/dns.rs` -- standalone engine functions ready for Tauri command integration in Plan 04.
</objective>

<execution_context>
@C:\Users\jfago\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jfago\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-core-scanning-engine/02-RESEARCH.md
@src-tauri/Cargo.toml
@src-tauri/src/scanner/types.rs
@src-tauri/src/scanner/ip_range.rs
@src-tauri/src/scanner/mod.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement async reverse DNS lookup</name>
  <files>
    src-tauri/src/scanner/dns.rs
    src-tauri/src/scanner/mod.rs
  </files>
  <action>
    Create src-tauri/src/scanner/dns.rs:

    Implement:
    pub async fn reverse_dns_lookup(ip: Ipv4Addr) -> Option<String>

    Implementation:
    1. Create a TokioAsyncResolver using system configuration (TokioAsyncResolver::tokio_from_system_conf()). If system config fails, fall back to ResolverConfig::default() + ResolverOpts::default().
    2. Wrap the resolver.reverse_lookup(IpAddr::V4(ip)) call with tokio::time::timeout of 2 seconds.
    3. On success, get the first PTR record name, convert to string, strip trailing dot if present.
    4. On timeout or lookup failure, return None (do NOT propagate errors -- DNS failure is expected for many hosts).

    Also implement a helper for batch lookups:
    pub async fn batch_reverse_dns(ips: &[Ipv4Addr], concurrency: usize) -> HashMap<Ipv4Addr, String>
    - Use Semaphore with the given concurrency to bound parallel DNS lookups
    - Spawn a task per IP, collect results into HashMap (only entries with successful lookups)
    - This is useful for resolving all discovered hosts after ping sweep

    NOTE: scanner/mod.rs already declares `pub mod dns;` (added by Plan 02-01). Just replace the stub file with the real implementation.

    IMPORTANT: Do NOT create the resolver per-call in the batch function. Create it once and share via Arc.
  </action>
  <verify>
    Run `cargo check` in src-tauri. The dns module should compile. Write a basic #[cfg(test)] test that calls reverse_dns_lookup(Ipv4Addr::new(127, 0, 0, 1)) and verifies it returns Some("localhost") or similar (may vary by system config -- test that it returns Some, not a specific value). Run `cargo test --lib` in src-tauri.
  </verify>
  <done>
    reverse_dns_lookup resolves IPs to hostnames asynchronously with 2s timeout. batch_reverse_dns resolves multiple IPs concurrently with bounded concurrency. DNS failures return None without panicking.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement concurrent ping sweep engine</name>
  <files>
    src-tauri/src/scanner/ping.rs
    src-tauri/src/scanner/mod.rs
  </files>
  <action>
    Create src-tauri/src/scanner/ping.rs:

    Implement the main ping sweep function:

    pub async fn ping_sweep(
        ips: Vec<Ipv4Addr>,
        timeout_ms: u64,
        concurrency: usize,
        cancel_token: CancellationToken,
        on_result: impl Fn(Ipv4Addr, bool) + Send + Sync + 'static,
    ) -> Vec<Ipv4Addr>

    Implementation:
    1. Create Semaphore with `concurrency` permits (cap at 100 max regardless of input, per research).
    2. Wrap on_result in Arc for sharing across tasks.
    3. For each IP in ips:
       a. Check cancel_token.is_cancelled() before spawning. If cancelled, break loop.
       b. Clone semaphore, cancel_token, callback Arc.
       c. Spawn tokio task that:
          - Acquires semaphore permit (owned)
          - Uses tokio::select! with cancel_token.cancelled() and the actual ping
          - Calls ping_host(ip, timeout_ms) to send ICMP echo
          - Calls on_result callback with (ip, is_alive)
          - Returns (ip, is_alive)

    4. Collect all JoinHandles, await them, filter to alive hosts only.
    5. Return Vec<Ipv4Addr> of alive hosts.

    Implement the individual host ping:

    async fn ping_host(ip: Ipv4Addr, timeout_ms: u64) -> bool

    Implementation using surge-ping:
    1. Create a surge_ping::Client using surge_ping::Client::new(&surge_ping::Config::default()) -- handle the Result (on Windows, this needs admin/Npcap).
    2. Create a pinger for the IP with client.pinger(IpAddr::V4(ip), PingIdentifier(random_u16)).await
    3. Set timeout on the pinger.
    4. Send one ping with pinger.ping(PingSequence(0), &[])
    5. If ping returns Ok within timeout, return true. Otherwise false.
    6. If Client::new fails (no admin/Npcap), log warning and return false for all hosts.

    IMPORTANT NOTES:
    - surge-ping requires admin privileges and Npcap on Windows. The Client::new() call will fail if these aren't available. Handle this gracefully -- if client creation fails, the entire sweep should return empty with an appropriate log, NOT panic.
    - Cap concurrency at min(concurrency, 100) to prevent socket exhaustion.
    - Use rand or a simple counter for PingIdentifier to avoid collisions.

    NOTE: scanner/mod.rs already declares `pub mod ping;` (added by Plan 02-01). Just replace the stub file with the real implementation.

    If surge-ping API doesn't match exactly (check docs), adapt accordingly. The key contract is: send ICMP echo, return bool alive/dead, with timeout and concurrency bounds.
  </action>
  <verify>
    Run `cargo check` in src-tauri. The ping module should compile without errors. Note: actual ping tests require admin privileges and network access, so unit tests should be minimal -- test that ping_sweep with empty IP list returns empty vec. Run `cargo test --lib`.
  </verify>
  <done>
    ping_sweep sends concurrent ICMP pings bounded by semaphore, respects cancellation token, calls callback per host, returns list of alive IPs. ping_host wraps surge-ping with timeout. Graceful handling when admin/Npcap unavailable.
  </done>
</task>

</tasks>

<verification>
- `cargo check` succeeds with scanner/ping.rs and scanner/dns.rs
- `cargo test --lib` passes all tests
- ping_sweep uses Semaphore (not FuturesUnordered) for concurrency
- All network operations wrapped with tokio::time::timeout
- CancellationToken checked before each host spawn and in tokio::select!
- DNS lookups use hickory-resolver (not std::net::lookup_host)
</verification>

<success_criteria>
- reverse_dns_lookup resolves IPs asynchronously with 2s timeout, returns None on failure
- ping_sweep discovers alive hosts using ICMP with bounded concurrency (max 100)
- Cancellation stops the sweep mid-execution without panic
- No blocking operations on the tokio runtime
- Graceful degradation when admin/Npcap unavailable
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-scanning-engine/02-02-SUMMARY.md`
</output>
